version: '3.8'

services:
  # Main Application
  backend:
    container_name: clientforge-backend
    build:
      context: .
      dockerfile: deployment/docker/development/Dockerfile.dev
    volumes:
      - ./backend:/app/backend
      - ./frontend:/app/frontend
      - ./ai:/app/ai
      - ./logs:/app/logs
    ports:
      - "3000:3000"
      - "3001:3001"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://crm:password@postgres:5432/clientforge
      - REDIS_URL=redis://redis:6379
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - JWT_SECRET=dev-jwt-secret-change-in-production
      - SESSION_SECRET=dev-session-secret-change-in-production
      - ENCRYPTION_KEY=dev-encryption-key-32-bytes-min
      - OPENAI_API_KEY=sk-dev-openai-key
      - ANTHROPIC_API_KEY=sk-ant-dev-anthropic-key
      - TS_NODE_PROJECT=backend/tsconfig.json
      - MONGODB_URL=mongodb://mongodb:27017/clientforge
      - MONGODB_URI=mongodb://mongodb:27017/clientforge
    depends_on:
      - postgres
      - redis
      - mongodb
      - elasticsearch
    healthcheck:
      test: ["CMD","curl","-f","http://localhost:3000/api/v1/health"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 20s

  # PostgreSQL Database with pgvector
  postgres:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_DB: clientforge
      POSTGRES_USER: crm
      POSTGRES_PASSWORD: password
      # Enable pg_stat_statements for monitoring
      POSTGRES_INITDB_ARGS: "-c shared_preload_libraries=pg_stat_statements"
    command: >
      postgres
      -c shared_preload_libraries=pg_stat_statements
      -c log_min_duration_statement=100
      -c log_statement=all
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  # MongoDB for unstructured data
  mongodb:
    image: mongo:6
    environment:
      MONGO_INITDB_ROOT_USERNAME: crm
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - mongo-data:/data/db
    ports:
      - "27017:27017"

  # Redis Cache (for BullMQ v3)
  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory-policy noeviction --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: clientforge-crm-elasticsearch-1
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data

  # RabbitMQ Message Queue
  rabbitmq:
    image: rabbitmq:3-management
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: crm
      RABBITMQ_DEFAULT_PASS: password

  # MinIO for file storage
  minio:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data

  # Albedo AI Service
  ai-service:
    build:
      context: ./ai
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    environment:
      - AI_MODEL_PATH=/models
      - TENSORFLOW_INTER_OP_PARALLELISM=2
    volumes:
      - ./ai/models:/models
      - ./ai/training:/training
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: clientforge-prometheus
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./config/prometheus/alerts.yml:/etc/prometheus/alerts.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    depends_on:
      - alertmanager
    restart: unless-stopped

  # Alertmanager for alert notifications
  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: clientforge-alertmanager
    volumes:
      - ./config/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"
    environment:
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER/PLACEHOLDER/PLACEHOLDER}
      - SLACK_CHANNEL=${SLACK_CHANNEL:-#clientforge-alerts}
      - ALERT_EMAIL_TO=${ALERT_EMAIL_TO:-alerts@example.com}
      - ALERT_EMAIL_FROM=${ALERT_EMAIL_FROM:-noreply@example.com}
      - SMTP_HOST=${SMTP_HOST:-smtp.example.com}
      - SMTP_PORT=${SMTP_PORT:-587}
      - SMTP_USERNAME=${SMTP_USERNAME:-user}
      - SMTP_PASSWORD=${SMTP_PASSWORD:-pass}
    restart: unless-stopped

  # Loki for log aggregation (infrastructure logs only)
  loki:
    image: grafana/loki:2.9.0
    container_name: clientforge-loki
    volumes:
      - ./config/loki/loki-config.yml:/etc/loki/loki-config.yml
      - loki-data:/loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/loki-config.yml
    restart: unless-stopped

  # Promtail for log shipping
  promtail:
    image: grafana/promtail:2.9.0
    container_name: clientforge-promtail
    volumes:
      - /var/log:/var/log:ro
      - ./logs:/app/logs:ro
      - ./config/promtail/promtail-config.yml:/etc/promtail/promtail-config.yml
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: -config.file=/etc/promtail/promtail-config.yml
    depends_on:
      - loki
    restart: unless-stopped

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: clientforge-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=redis-datasource
      - GF_SERVER_ROOT_URL=http://localhost:3005
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/PLACEHOLDER/PLACEHOLDER/PLACEHOLDER}
      - SLACK_CHANNEL=${SLACK_CHANNEL:-#clientforge-alerts}
      - ALERT_EMAIL_TO=${ALERT_EMAIL_TO:-alerts@example.com}
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./config/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./dashboards:/var/lib/grafana/dashboards
      - ./config/grafana/provisioning/alerting:/etc/grafana/provisioning/alerting
    ports:
      - "3005:3000"
    depends_on:
      - prometheus
      - loki
    restart: unless-stopped

volumes:
  postgres-data:
  mongo-data:
  redis-data:
  elasticsearch-data:
  minio-data:
  prometheus-data:
  loki-data:
  grafana-data:
