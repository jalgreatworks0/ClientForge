# ES-003: ElasticsearchUnavailable

**Severity**: Critical
**HTTP Status**: 503
**Retry Strategy**: Safe
**Notify**: Yes

## Description

Elasticsearch cluster is unavailable or unreachable. This affects all search functionality and analytics features.

## Impact

- Global search disabled
- Deal/Contact/Account search unavailable
- Analytics dashboards may show stale data
- Search-powered features degraded

## Detection

### Signals
- Port 9200 unreachable
- HTTP 503 responses from Elasticsearch
- Health check shows cluster status "red"
- Prometheus alert: `elasticsearch_cluster_health_status == 0`

### Log Pattern
```
logger.error("[ERROR]", {
  id: "ES-003",
  name: "ElasticsearchUnavailable",
  severity: "critical"
})
```

### Grafana Dashboard
- **Dashboard**: Search Health
- **Panel**: Elasticsearch Cluster Status
- **Alert**: Elasticsearch Down

## Immediate Actions

### 1. Verify Service Status
```bash
# Check if Docker container is running
docker ps | grep elasticsearch

# Check health endpoint
curl http://localhost:9200/_cluster/health?pretty

# Check container logs
docker logs clientforge-crm-elasticsearch-1 --tail 50
```

### 2. Check Cluster Status
```bash
# Get cluster health
curl -X GET "localhost:9200/_cluster/health?pretty"

# Expected response:
# {
#   "cluster_name" : "clientforge-search",
#   "status" : "green" or "yellow",
#   "timed_out" : false,
#   "number_of_nodes" : 1
# }
```

### 3. Review Resource Usage
```bash
# Check disk space (ES needs at least 10% free)
df -h

# Check memory usage
docker stats clientforge-crm-elasticsearch-1

# Check JVM heap
curl -X GET "localhost:9200/_nodes/stats/jvm?pretty"
```

## Troubleshooting Steps

### Step 1: Restart Elasticsearch Container
```bash
cd /path/to/clientforge-crm
docker-compose restart elasticsearch

# Wait for cluster to initialize (30-60 seconds)
sleep 60

# Verify cluster health
npm run es:check-status
```

### Step 2: Check Disk Space
```bash
# ES requires at least 10% free disk space
df -h | grep /var/lib/docker

# If disk full, clean up old indices
curl -X DELETE "localhost:9200/logs-*-2024.01.*"
```

### Step 3: Check JVM Heap
```bash
# View current heap usage
curl -X GET "localhost:9200/_nodes/stats/jvm?pretty" | grep heap_used_percent

# If > 85%, increase heap size in docker-compose.yml:
# ES_JAVA_OPTS: "-Xms2g -Xmx2g"
```

### Step 4: Check Index Status
```bash
# List all indices
curl -X GET "localhost:9200/_cat/indices?v"

# Check for RED indices
curl -X GET "localhost:9200/_cluster/health?level=indices&pretty"
```

## Resolution Steps

### Option 1: Service Restart (Quickest)
```bash
docker-compose restart elasticsearch

# Wait for green status
while [ $(curl -s http://localhost:9200/_cluster/health | jq -r '.status') != "green" ]; do
  echo "Waiting for Elasticsearch..."
  sleep 5
done
```
**Expected Time**: 1-2 minutes

### Option 2: Clear Disk Space
If disk is full:
```bash
# Delete old logs indices
curl -X DELETE "localhost:9200/logs-*-2024.*"

# Run ILM policies
npm run es:setup-ilm
```
**Expected Time**: 2-5 minutes

### Option 3: Rebuild Indices
If indices are corrupted:
```bash
# Delete corrupted index
curl -X DELETE "localhost:9200/deals"

# Rebuild from database
# This will be handled automatically on next API call
```
**Expected Time**: 5-10 minutes

### Option 4: Full Cluster Restart
```bash
docker-compose down elasticsearch
docker volume rm clientforge-crm_es_data
docker-compose up -d elasticsearch

# Reindex all data
npm run es:reindex-all
```
**Expected Time**: 15-30 minutes
**Data Loss**: All search data will be rebuilt from PostgreSQL

## Prevention

1. **Monitoring**: Configure Prometheus alerts for cluster health
2. **Disk Space**: Alert when disk usage > 80%
3. **ILM Policies**: Automatically delete indices older than 90 days
4. **Backup**: Snapshot to MinIO every 6 hours
5. **Resource Limits**: Set memory limits to prevent OOM

## Related Errors

- **ES-001**: IndexMissing
- **ES-002**: SearchFailed
- **QUEUE-001**: WorkerDown (may cause search lag)

## Escalation

### Level 1 (0-5 minutes)
- On-call engineer investigates
- Check monitoring dashboards
- Attempt service restart

### Level 2 (5-15 minutes)
- Senior DevOps engineer paged
- Consider disabling search features
- Investigate disk space issues

### Level 3 (15+ minutes)
- CTO notified
- Rebuild search indices from database
- Consider external Elasticsearch service

## Post-Incident

1. **Root Cause Analysis**: Document cause of failure
2. **Incident Report**: File in `docs/incidents/`
3. **Capacity Planning**: Review disk/memory limits
4. **Prevention**: Update ILM policies if needed

## References

- [Elasticsearch Docker Documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html)
- [Cluster Health API](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html)
- [ClientForge Search Setup Guide](docs/search/README.md)

---

**Last Updated**: 2025-11-11
**Runbook Version**: 1.0
**Owner**: DevOps Team
