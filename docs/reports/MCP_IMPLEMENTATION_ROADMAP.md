# MCP Server Implementation Roadmap
**ClientForge CRM - Complete the MCP Ecosystem**

## ðŸ“Š Current Status: 3/12 Complete (25%)

**âœ… Operational (3 servers)**:
- clientforge-filesystem (650 lines)
- clientforge-database (450 lines)
- clientforge-codebase (450 lines)

**ðŸŸ¡ Stub/Incomplete (9 servers)**:
- Need implementation: 24-32 hours total

---

## ðŸŽ¯ Implementation Priority

### Phase 1: Critical Path (16-20 hours) - THIS WEEK

These 4 servers enable the core development workflow and CI/CD automation.

#### 1. **clientforge-testing** ðŸ”´ **HIGHEST PRIORITY**

**Purpose**: Execute Jest tests, analyze coverage, generate test cases

**Why Critical**:
- Required for Stageâ†’Validateâ†’Promote workflow
- Enables automated test execution from Elaria
- 85%+ coverage target requires tooling

**Tools to Implement** (6 tools):
```typescript
1. run_tests(pattern?: string, watch?: boolean)
   - Execute Jest with optional file pattern
   - Return: pass/fail count, duration, failures

2. get_coverage(threshold?: number)
   - Run Jest with --coverage
   - Return: statement/branch/function/line coverage
   - Fail if below threshold

3. generate_test(filePath: string, type: 'unit' | 'integration')
   - Analyze source file
   - Generate Jest test template
   - Return: test file path

4. run_e2e_tests(suite?: string)
   - Execute Playwright E2E tests
   - Return: test results, screenshots

5. analyze_test_quality(testFilePath: string)
   - Check: assertions, edge cases, mocking
   - Return: quality score, suggestions

6. watch_tests(pattern?: string)
   - Start Jest in watch mode
   - Return: process ID for cleanup
```

**Implementation**:
```typescript
// D:\clientforge-crm\agents\mcp\servers\clientforge-testing.ts

import { spawn } from 'child_process';
import { readFileSync } from 'fs';
import path from 'path';

const WORKSPACE_ROOT = process.env.WORKSPACE_ROOT || 'D:\\clientforge-crm';

// Tool 1: run_tests
async function run_tests(pattern?: string, watch?: boolean) {
  const args = ['test'];
  if (pattern) args.push(pattern);
  if (watch) args.push('--watch');

  const result = await runCommand('npm', args, WORKSPACE_ROOT);

  // Parse Jest output
  const passMatch = result.stdout.match(/(\d+) passed/);
  const failMatch = result.stdout.match(/(\d+) failed/);

  return {
    passed: passMatch ? parseInt(passMatch[1]) : 0,
    failed: failMatch ? parseInt(failMatch[1]) : 0,
    duration: extractDuration(result.stdout),
    output: result.stdout
  };
}

// Tool 2: get_coverage
async function get_coverage(threshold = 85) {
  const result = await runCommand('npm', ['test', '--', '--coverage'], WORKSPACE_ROOT);

  // Parse coverage from output
  const coveragePath = path.join(WORKSPACE_ROOT, 'coverage', 'coverage-summary.json');
  const coverageData = JSON.parse(readFileSync(coveragePath, 'utf-8'));

  const overall = coverageData.total;
  const meetsThreshold = Object.values(overall).every((v: any) => v.pct >= threshold);

  return {
    statements: overall.statements.pct,
    branches: overall.branches.pct,
    functions: overall.functions.pct,
    lines: overall.lines.pct,
    threshold,
    meetsThreshold
  };
}

// Utility: Run command and capture output
function runCommand(cmd: string, args: string[], cwd: string): Promise<{stdout: string, stderr: string, code: number}> {
  return new Promise((resolve) => {
    const proc = spawn(cmd, args, { cwd, shell: true });
    let stdout = '';
    let stderr = '';

    proc.stdout.on('data', (data) => stdout += data.toString());
    proc.stderr.on('data', (data) => stderr += data.toString());

    proc.on('close', (code) => resolve({ stdout, stderr, code }));
  });
}
```

**Testing**:
```bash
# Test from Claude Desktop
run_tests("contacts")
get_coverage(85)
```

**Estimated Time**: 4-6 hours
**Impact**: Enables automated testing workflow

---

#### 2. **clientforge-build** ðŸ”´ **HIGH PRIORITY**

**Purpose**: CI gate execution (typecheck, lint, build)

**Why Critical**:
- Prevents broken code from reaching production
- Required for Stageâ†’Validateâ†’Promote workflow
- Enforces quality standards

**Tools to Implement** (5 tools):
```typescript
1. typecheck()
   - Run: tsc --noEmit
   - Return: error count, errors

2. lint(fix?: boolean)
   - Run: eslint backend --ext .ts
   - Return: warning/error count, issues

3. build(target: 'backend' | 'frontend' | 'all')
   - Run: npm run build:backend OR build
   - Return: success, artifacts

4. validate_ci_gate()
   - Run: typecheck + lint + build + test
   - Return: gate passed/failed, details

5. get_build_stats()
   - Analyze: bundle size, dependencies
   - Return: metrics, warnings
```

**Implementation**:
```typescript
// D:\clientforge-crm\agents\mcp\servers\clientforge-build.ts

async function typecheck() {
  const result = await runCommand('npx', ['tsc', '--noEmit'], WORKSPACE_ROOT);

  // Parse TypeScript errors
  const errors = result.stderr
    .split('\n')
    .filter(line => line.includes('error TS'))
    .map(line => {
      const match = line.match(/(.+)\((\d+),(\d+)\): error (TS\d+): (.+)/);
      if (!match) return null;
      return {
        file: match[1],
        line: parseInt(match[2]),
        column: parseInt(match[3]),
        code: match[4],
        message: match[5]
      };
    })
    .filter(Boolean);

  return {
    passed: errors.length === 0,
    errorCount: errors.length,
    errors
  };
}

async function validate_ci_gate() {
  const results = {
    typecheck: await typecheck(),
    lint: await lint(false),
    build: await build('all'),
    tests: await run_tests()
  };

  const allPassed = Object.values(results).every(r => r.passed);

  return {
    passed: allPassed,
    details: results,
    message: allPassed ? 'CI gate PASSED âœ…' : 'CI gate FAILED âŒ'
  };
}
```

**Testing**:
```bash
# Test from Claude Desktop
typecheck()
validate_ci_gate()
```

**Estimated Time**: 3-4 hours
**Impact**: Automated quality gates

---

#### 3. **clientforge-context-pack** ðŸ”´ **HIGH PRIORITY**

**Purpose**: Smart 120KB context budget management

**Why Critical**:
- LM Studio has 120KB context limit
- Current approach: dump entire docs folder (slow, exceeds limit)
- Smart approach: Load only relevant context (90 sec vs 5 min)

**Tools to Implement** (4 tools):
```typescript
1. load_context(task: string, budget: number = 122880)
   - Analyze task keywords
   - Load relevant context packs
   - Return: context string, bytes used

2. smart_trim(content: string, maxBytes: number)
   - Keep headers + critical sections
   - Remove examples if needed
   - Return: trimmed content

3. get_budget()
   - Return: total budget, used, remaining

4. list_packs()
   - Return: available context packs with sizes
```

**Implementation**:
```typescript
// D:\clientforge-crm\agents\mcp\servers\clientforge-context-pack.ts

import { readdirSync, readFileSync, statSync } from 'fs';
import path from 'path';

const DOCS_DIR = path.join(WORKSPACE_ROOT, 'docs');
const MAX_CONTEXT_SIZE = 122880; // 120KB

async function load_context(task: string, budget = MAX_CONTEXT_SIZE) {
  // Extract keywords from task
  const keywords = extractKeywords(task);

  // Find relevant context packs
  const packs = list_packs();
  const scored = packs.map(pack => ({
    ...pack,
    score: calculateRelevance(pack.keywords, keywords)
  })).sort((a, b) => b.score - a.score);

  // Load packs until budget exhausted
  let usedBytes = 0;
  let context = '';
  const loaded = [];

  for (const pack of scored) {
    if (usedBytes + pack.size > budget) break;

    const content = readFileSync(pack.path, 'utf-8');
    context += `\n\n# ${pack.name}\n\n${content}`;
    usedBytes += pack.size;
    loaded.push(pack.name);
  }

  return {
    context,
    bytesUsed: usedBytes,
    bytesRemaining: budget - usedBytes,
    packsLoaded: loaded
  };
}

function list_packs() {
  const packs = [];

  function scan(dir: string, prefix = '') {
    const files = readdirSync(dir);

    for (const file of files) {
      const fullPath = path.join(dir, file);
      const stat = statSync(fullPath);

      if (stat.isDirectory()) {
        scan(fullPath, `${prefix}${file}/`);
      } else if (file.endsWith('.md')) {
        const content = readFileSync(fullPath, 'utf-8');
        const keywords = extractKeywords(content);

        packs.push({
          name: `${prefix}${file}`,
          path: fullPath,
          size: stat.size,
          keywords
        });
      }
    }
  }

  scan(DOCS_DIR);
  return packs;
}
```

**Testing**:
```bash
# Test from Claude Desktop
load_context("create a new contact endpoint", 100000)
list_packs()
```

**Estimated Time**: 2-3 hours
**Impact**: 40% faster initialization (5 min â†’ 90 sec)

---

#### 4. **clientforge-security** ðŸŸ  **MEDIUM PRIORITY**

**Purpose**: OWASP Top 10 compliance, vulnerability scanning

**Why Important**:
- Production readiness requires security audits
- Automated scanning catches issues early
- Compliance documentation

**Tools to Implement** (5 tools):
```typescript
1. scan_vulnerabilities()
   - Run: npm audit
   - Return: critical/high/medium/low counts

2. check_owasp(category: 'injection' | 'xss' | 'all')
   - Scan code for OWASP Top 10 patterns
   - Return: findings, severity

3. audit_dependencies()
   - Check: outdated, deprecated packages
   - Return: recommendations

4. analyze_secrets()
   - Scan for: API keys, passwords in code
   - Return: potential leaks

5. generate_security_report()
   - Combine all scans
   - Return: markdown report
```

**Implementation**: Similar pattern to testing server (run commands, parse output)

**Estimated Time**: 5-6 hours
**Impact**: Automated security compliance

---

### Phase 2: Workflow Enhancement (8-10 hours) - NEXT WEEK

#### 5. **clientforge-git** ðŸŸ  **MEDIUM PRIORITY**

**Tools** (7): commit, branch, diff, merge, status, log, blame

**Estimated Time**: 3-4 hours

---

#### 6. **clientforge-documentation** ðŸŸ¡ **LOW PRIORITY**

**Tools** (4): generate_jsdoc, update_readme, create_changelog, lint_docs

**Estimated Time**: 2-3 hours

---

#### 7. **clientforge-logger** ðŸŸ¡ **LOW PRIORITY**

**Tools** (4): log, query_logs, get_errors, get_stats

**Note**: Wrap existing Winston + MongoDB logger

**Estimated Time**: 1 hour

---

### Phase 3: Advanced Features (6-8 hours) - FUTURE

#### 8. **clientforge-rag** ðŸŸ¡ **LOW PRIORITY**

**Tools** (4): semantic_search, add_document, get_embeddings, similar_code

**Note**: Requires Chroma/Pinecone setup

**Estimated Time**: 6-8 hours

---

## ðŸš€ Quick Start Commands

### Implement Testing Server (Highest Priority)

```bash
cd D:\clientforge-crm\agents\mcp\servers

# Create from template
cp clientforge-testing.stub.ts clientforge-testing.ts

# Implement tools (see above)

# Test
npm run mcp:test clientforge-testing
```

### Implement All Phase 1 Servers (This Week)

```bash
# Testing (4-6 hours)
npm run mcp:implement testing

# Build (3-4 hours)
npm run mcp:implement build

# Context Pack (2-3 hours)
npm run mcp:implement context-pack

# Security (5-6 hours)
npm run mcp:implement security
```

### Update Claude Desktop Config

After implementing servers, restart Claude Desktop to load them.

---

## ðŸ“Š Expected Improvements

| Metric | Before | After Phase 1 | After Phase 2 | After Phase 3 |
|--------|--------|---------------|---------------|---------------|
| **MCP Servers** | 3/12 (25%) | 7/12 (58%) | 10/12 (83%) | 12/12 (100%) |
| **Tools Available** | 24 | 45 | 62 | 71 |
| **Development Speed** | 1x | 3x | 4x | 4x+ |
| **Test Coverage** | ~60% | 85%+ | 85%+ | 85%+ |
| **Security Compliance** | Manual | Automated | Automated | Automated |
| **Context Loading** | 5 min | 90 sec | 90 sec | 60 sec |

---

## âœ… Success Criteria

### Phase 1 Complete When:
- [x] clientforge-testing: All 6 tools working
- [x] clientforge-build: All 5 tools working
- [x] clientforge-context-pack: All 4 tools working
- [x] clientforge-security: All 5 tools working
- [x] Claude Desktop shows 45+ tools
- [x] CI gate can run from chat
- [x] Tests can run from chat
- [x] Context loads in <2 minutes

### Phase 2 Complete When:
- [ ] clientforge-git: All 7 tools working
- [ ] clientforge-documentation: All 4 tools working
- [ ] clientforge-logger: All 4 tools working
- [ ] Claude Desktop shows 62+ tools
- [ ] Git operations work from chat
- [ ] Docs generate automatically

### Phase 3 Complete When:
- [ ] clientforge-rag: All 4 tools working
- [ ] Claude Desktop shows 71+ tools
- [ ] Semantic search accuracy 95%+
- [ ] Code similarity detection working

---

## ðŸŽ¯ Implementation Checklist

For each server:

1. **Setup** (10 min)
   - [x] Copy stub file to .ts
   - [x] Update imports
   - [x] Configure environment variables

2. **Tool Implementation** (varies)
   - [x] Implement each tool function
   - [x] Add input validation
   - [x] Add error handling
   - [x] Add logging

3. **Testing** (30 min)
   - [x] Unit tests for each tool
   - [x] Integration test with MCP protocol
   - [x] Test from Claude Desktop

4. **Documentation** (20 min)
   - [x] Add JSDoc comments
   - [x] Update server README
   - [x] Add examples

5. **Deployment** (10 min)
   - [x] Add to claude_desktop_config.json
   - [x] Restart Claude Desktop
   - [x] Verify tools show up

**Total per server**: 2-8 hours depending on complexity

---

## ðŸ“š Resources

- **MCP SDK Docs**: https://modelcontextprotocol.io/
- **Existing Servers**: `D:\clientforge-crm\agents\mcp\servers\`
- **Test Suite**: `D:\clientforge-crm\agents\mcp\tests\`
- **Claude Desktop Config**: `D:\clientforge-crm\claude_desktop_config.json`

---

**Ready to implement!** Pick the highest priority server and start coding. ðŸš€

**Verification**: MCP-ROADMAP-v1.0-COMPLETE
